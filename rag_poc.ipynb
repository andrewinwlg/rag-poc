{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNs5wWsOeR/Kd36fI2ie9TU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewinwlg/rag-poc/blob/main/rag_poc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6p9Csmob6aB",
        "outputId": "1ab4f777-ca8e-4756-a571-c45059531d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 RAG POC on Free GPU - Google Colab\n",
            "Make sure Runtime -> Change runtime type -> GPU is selected!\n",
            "============================================================\n",
            "📦 Installing packages...\n",
            "✅ All packages installed!\n"
          ]
        }
      ],
      "source": [
        "# 🚀 RAG POC on Free GPU - Google Colab\n",
        "print(\"🚀 RAG POC on Free GPU - Google Colab\")\n",
        "print(\"Make sure Runtime -> Change runtime type -> GPU is selected!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Install dependencies\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_and_import(package):\n",
        "    try:\n",
        "        __import__(package)\n",
        "    except ImportError:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "packages = [\n",
        "    \"sentence-transformers\",\n",
        "    \"transformers\",\n",
        "    \"torch\",\n",
        "    \"chromadb\",\n",
        "    \"requests\"\n",
        "]\n",
        "\n",
        "print(\"📦 Installing packages...\")\n",
        "for package in packages:\n",
        "    install_and_import(package)\n",
        "\n",
        "print(\"✅ All packages installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone RAG POC Repository\n",
        "import os\n",
        "if os.path.exists('rag-poc'):\n",
        "    os.chdir('rag-poc')\n",
        "    os.system('git pull')\n",
        "else:\n",
        "    os.system('git clone https://github.com/andrewinwlg/rag-poc.git')\n",
        "    os.chdir('rag-poc')\n",
        "\n",
        "print(\"✅ Repository ready!\")\n",
        "os.system('ls -la data/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61G1Y3zDdbKz",
        "outputId": "8f835de8-e3b2-4eef-e5b6-39057d11c633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Repository ready!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 - Qwen 2.5-Coder Setup\n",
        "print(\"🤖 Setting up Ollama with Qwen 2.5-Coder...\")\n",
        "os.system('curl -fsSL https://ollama.ai/install.sh | sh')\n",
        "\n",
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# Start Ollama server\n",
        "ollama_process = subprocess.Popen(\n",
        "    [\"ollama\", \"serve\"],\n",
        "    stdout=subprocess.DEVNULL,\n",
        "    stderr=subprocess.DEVNULL\n",
        ")\n",
        "\n",
        "time.sleep(10)\n",
        "\n",
        "# Download Qwen 2.5-Coder model\n",
        "print(\"📥 Downloading Qwen 2.5-Coder-7B-Instruct (this is perfect for API docs!)...\")\n",
        "print(\"⏱️ This will take 3-4 minutes but it's worth it for much better responses...\")\n",
        "\n",
        "try:\n",
        "    result = os.system('ollama pull qwen2.5-coder:7b-instruct')\n",
        "    if result == 0:\n",
        "        print(\"✅ Qwen 2.5-Coder ready! This model excels at technical documentation.\")\n",
        "        current_model = \"qwen2.5-coder:7b-instruct\"\n",
        "    else:\n",
        "        print(\"⚠️ Qwen download failed, falling back to gemma:2b\")\n",
        "        os.system('ollama pull gemma:2b')\n",
        "        current_model = \"gemma:2b\"\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Error downloading Qwen: {e}\")\n",
        "    print(\"📥 Falling back to gemma:2b...\")\n",
        "    os.system('ollama pull gemma:2b')\n",
        "    current_model = \"gemma:2b\"\n",
        "\n",
        "# Store the model globally\n",
        "globals()['current_model'] = current_model\n",
        "\n",
        "# Test connection\n",
        "try:\n",
        "    response = requests.get(\"http://localhost:11434/api/version\", timeout=5)\n",
        "    if response.status_code == 200:\n",
        "        print(f\"✅ Ollama ready with {current_model}!\")\n",
        "        print(\"🚀 This model should give much better API documentation responses!\")\n",
        "    else:\n",
        "        print(\"⚠️ Ollama may not be ready - try again\")\n",
        "except:\n",
        "    print(\"⚠️ Connection issue - run this cell again\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P30uh8EWdcNm",
        "outputId": "e453c777-65b6-4f28-cef0-f65f8dc689af"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Setting up Ollama with Qwen 2.5-Coder...\n",
            "📥 Downloading Qwen 2.5-Coder-7B-Instruct (this is perfect for API docs!)...\n",
            "⏱️ This will take 3-4 minutes but it's worth it for much better responses...\n",
            "✅ Qwen 2.5-Coder ready! This model excels at technical documentation.\n",
            "✅ Ollama ready with qwen2.5-coder:7b-instruct!\n",
            "🚀 This model should give much better API documentation responses!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Cell 4 - Better JSON Processing\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "import uuid\n",
        "import json\n",
        "\n",
        "print(\"🧠 Loading embedding model...\")\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "print(\"🗄️ Setting up vector database...\")\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Clear existing collection\n",
        "try:\n",
        "    client.delete_collection(\"rag_documents\")\n",
        "    print(\"🗑️ Deleted existing collection\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "collection = client.create_collection(\"rag_documents\")\n",
        "\n",
        "def chunk_text(text, chunk_size=500, overlap=50):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), chunk_size - overlap):\n",
        "        chunk = words[i:i+chunk_size]\n",
        "        if len(chunk) > 0:\n",
        "            chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "def parse_openapi_json(data):\n",
        "    \"\"\"Convert OpenAPI/Swagger JSON to meaningful text chunks\"\"\"\n",
        "    chunks = []\n",
        "\n",
        "    # 1. API Overview\n",
        "    if 'info' in data:\n",
        "        info = data['info']\n",
        "        overview = f\"\"\"\n",
        "API Name: {info.get('title', 'Unknown')}\n",
        "Version: {info.get('version', 'Unknown')}\n",
        "Description: {info.get('description', 'No description')}\n",
        "\"\"\"\n",
        "        chunks.append((\"API Overview\", overview.strip()))\n",
        "\n",
        "    # 2. Server Information\n",
        "    if 'servers' in data:\n",
        "        server_info = \"API Servers:\\n\"\n",
        "        for server in data['servers']:\n",
        "            server_info += f\"- URL: {server.get('url', '')}\\n\"\n",
        "            server_info += f\"  Description: {server.get('description', 'No description')}\\n\"\n",
        "        chunks.append((\"Server Information\", server_info.strip()))\n",
        "\n",
        "    # 3. Individual Endpoints (this is key!)\n",
        "    if 'paths' in data:\n",
        "        for path, methods in data['paths'].items():\n",
        "            for method, details in methods.items():\n",
        "                if isinstance(details, dict):\n",
        "                    endpoint_text = f\"\"\"\n",
        "Endpoint: {method.upper()} {path}\n",
        "Summary: {details.get('summary', 'No summary')}\n",
        "Description: {details.get('description', 'No description')}\n",
        "\"\"\"\n",
        "\n",
        "                    # Add parameters\n",
        "                    if 'parameters' in details:\n",
        "                        endpoint_text += \"\\nParameters:\\n\"\n",
        "                        for param in details['parameters']:\n",
        "                            endpoint_text += f\"- {param.get('name', '')}: {param.get('description', '')}\\n\"\n",
        "                            endpoint_text += f\"  Type: {param.get('schema', {}).get('type', 'unknown')}\\n\"\n",
        "                            endpoint_text += f\"  Required: {param.get('required', False)}\\n\"\n",
        "\n",
        "                    # Add request body info\n",
        "                    if 'requestBody' in details:\n",
        "                        endpoint_text += f\"\\nRequest Body Required: {details['requestBody'].get('required', False)}\\n\"\n",
        "                        if 'content' in details['requestBody']:\n",
        "                            endpoint_text += \"Content Types: \" + \", \".join(details['requestBody']['content'].keys()) + \"\\n\"\n",
        "\n",
        "                    # Add response info\n",
        "                    if 'responses' in details:\n",
        "                        endpoint_text += \"\\nResponses:\\n\"\n",
        "                        for code, response in details['responses'].items():\n",
        "                            endpoint_text += f\"- {code}: {response.get('description', 'No description')}\\n\"\n",
        "\n",
        "                    chunks.append((f\"Endpoint {method.upper()} {path}\", endpoint_text.strip()))\n",
        "\n",
        "    # 4. Components/Schemas\n",
        "    if 'components' in data and 'schemas' in data['components']:\n",
        "        for schema_name, schema_def in data['components']['schemas'].items():\n",
        "            schema_text = f\"\"\"\n",
        "Data Model: {schema_name}\n",
        "Type: {schema_def.get('type', 'object')}\n",
        "Description: {schema_def.get('description', 'No description')}\n",
        "\"\"\"\n",
        "            if 'properties' in schema_def:\n",
        "                schema_text += \"\\nProperties:\\n\"\n",
        "                for prop_name, prop_def in schema_def['properties'].items():\n",
        "                    schema_text += f\"- {prop_name}: {prop_def.get('type', 'unknown')} - {prop_def.get('description', 'No description')}\\n\"\n",
        "\n",
        "            chunks.append((f\"Schema {schema_name}\", schema_text.strip()))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Process documents\n",
        "documents = []\n",
        "metadatas = []\n",
        "ids = []\n",
        "\n",
        "data_path = Path(\"data\")\n",
        "for filepath in data_path.glob(\"**/*\"):\n",
        "    if filepath.suffix in [\".md\", \".txt\", \".py\"]:\n",
        "        # Handle text files normally\n",
        "        try:\n",
        "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "                text = f.read()\n",
        "\n",
        "            if text.strip():\n",
        "                chunks = chunk_text(text)\n",
        "                for i, chunk in enumerate(chunks):\n",
        "                    documents.append(chunk)\n",
        "                    metadatas.append({\n",
        "                        \"filename\": filepath.name,\n",
        "                        \"chunk_index\": i,\n",
        "                        \"source_type\": \"text\"\n",
        "                    })\n",
        "                    ids.append(f\"{filepath.name}_{i}_{str(uuid.uuid4())[:8]}\")\n",
        "\n",
        "                print(f\"✅ Processed {filepath.name}: {len(chunks)} text chunks\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error processing {filepath.name}: {e}\")\n",
        "\n",
        "    elif filepath.suffix == \".json\":\n",
        "        # Enhanced JSON processing\n",
        "        try:\n",
        "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            # Check if it's an OpenAPI spec\n",
        "            if 'openapi' in data or 'swagger' in data:\n",
        "                structured_chunks = parse_openapi_json(data)\n",
        "\n",
        "                for i, (section_name, content) in enumerate(structured_chunks):\n",
        "                    documents.append(content)\n",
        "                    metadatas.append({\n",
        "                        \"filename\": filepath.name,\n",
        "                        \"chunk_index\": i,\n",
        "                        \"source_type\": \"openapi\",\n",
        "                        \"section\": section_name\n",
        "                    })\n",
        "                    ids.append(f\"{filepath.name}_{section_name}_{str(uuid.uuid4())[:8]}\")\n",
        "\n",
        "                print(f\"✅ Processed {filepath.name}: {len(structured_chunks)} API chunks\")\n",
        "            else:\n",
        "                # Fallback for other JSON\n",
        "                text = json.dumps(data, indent=2)\n",
        "                chunks = chunk_text(text)\n",
        "                for i, chunk in enumerate(chunks):\n",
        "                    documents.append(chunk)\n",
        "                    metadatas.append({\n",
        "                        \"filename\": filepath.name,\n",
        "                        \"chunk_index\": i,\n",
        "                        \"source_type\": \"json\"\n",
        "                    })\n",
        "                    ids.append(f\"{filepath.name}_{i}_{str(uuid.uuid4())[:8]}\")\n",
        "\n",
        "                print(f\"✅ Processed {filepath.name}: {len(chunks)} JSON chunks\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error processing JSON {filepath.name}: {e}\")\n",
        "\n",
        "# Add to vector database\n",
        "if documents:\n",
        "    collection.add(\n",
        "        documents=documents,\n",
        "        metadatas=metadatas,\n",
        "        ids=ids\n",
        "    )\n",
        "    print(f\"✅ Vector database ready with {len(documents)} chunks!\")\n",
        "\n",
        "    # Show what we got\n",
        "    print(\"\\n📊 Chunk breakdown:\")\n",
        "    source_types = {}\n",
        "    for meta in metadatas:\n",
        "        source_type = meta.get('source_type', 'unknown')\n",
        "        source_types[source_type] = source_types.get(source_type, 0) + 1\n",
        "\n",
        "    for source_type, count in source_types.items():\n",
        "        print(f\"  {source_type}: {count} chunks\")\n",
        "else:\n",
        "    print(\"❌ No documents found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdXW2Y31djhL",
        "outputId": "223d9756-ff32-4bc8-d791-e657b73762b4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 Loading embedding model...\n",
            "🗄️ Setting up vector database...\n",
            "🗑️ Deleted existing collection\n",
            "✅ Processed troubleshooting.md: 2 text chunks\n",
            "✅ Processed openapi.json: 933 API chunks\n",
            "✅ Processed sample.md: 1 text chunks\n",
            "✅ Vector database ready with 936 chunks!\n",
            "\n",
            "📊 Chunk breakdown:\n",
            "  text: 3 chunks\n",
            "  openapi: 933 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 - Enhanced for Qwen 2.5-Coder\n",
        "def query_rag(question, top_k=5, model=None, verbose=False):\n",
        "    \"\"\"Query the RAG system with Qwen 2.5-Coder optimizations\"\"\"\n",
        "    if model is None:\n",
        "        model = globals().get('current_model', 'qwen2.5-coder:7b-instruct')\n",
        "\n",
        "    print(f\"🔍 Searching for: '{question}'\")\n",
        "\n",
        "    # Query vector database\n",
        "    results = collection.query(\n",
        "        query_texts=[question],\n",
        "        n_results=top_k\n",
        "    )\n",
        "\n",
        "    if not results['documents'][0]:\n",
        "        return \"❌ No relevant documents found.\"\n",
        "\n",
        "    # Build context with better formatting for code models\n",
        "    context_chunks = results['documents'][0]\n",
        "    context_sections = []\n",
        "\n",
        "    for i, (chunk, meta) in enumerate(zip(context_chunks, results['metadatas'][0])):\n",
        "        section_name = meta.get('section', f\"Section {i+1}\")\n",
        "        source_type = meta.get('source_type', 'unknown')\n",
        "        filename = meta.get('filename', 'unknown')\n",
        "\n",
        "        formatted_chunk = f\"\"\"\n",
        "## {section_name} (from {filename})\n",
        "{chunk}\n",
        "\"\"\"\n",
        "        context_sections.append(formatted_chunk)\n",
        "\n",
        "    context = \"\\n\".join(context_sections)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n📄 Retrieved Context:\")\n",
        "        for i, (chunk, meta) in enumerate(zip(context_chunks, results['metadatas'][0])):\n",
        "            section = meta.get('section', 'Unknown')\n",
        "            source_type = meta.get('source_type', 'text')\n",
        "            print(f\"📋 Chunk {i+1} [{source_type}] ({section}): {chunk[:200]}...\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "    # Specialized prompt for Qwen 2.5-Coder\n",
        "    prompt = f\"\"\"You are a technical documentation assistant specializing in API documentation and code analysis.\n",
        "\n",
        "Given the following technical documentation context, provide a precise and helpful answer to the user's question.\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "<question>\n",
        "{question}\n",
        "</question>\n",
        "\n",
        "Instructions:\n",
        "- Base your answer strictly on the provided context\n",
        "- For API questions, include specific endpoint paths, HTTP methods, and parameter details\n",
        "- For code questions, reference exact function names, parameters, and examples\n",
        "- If information is missing from the context, clearly state what's not available\n",
        "- Use proper technical terminology\n",
        "- Be concise but complete\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    # Query LLM with optimized settings for Qwen\n",
        "    try:\n",
        "        print(f\"🤖 Asking {model}...\")\n",
        "        response = requests.post(\n",
        "            \"http://localhost:11434/api/generate\",\n",
        "            json={\n",
        "                \"model\": model,\n",
        "                \"prompt\": prompt,\n",
        "                \"stream\": False,\n",
        "                \"options\": {\n",
        "                    \"temperature\": 0.2,    # Lower for more factual responses\n",
        "                    \"top_p\": 0.8,         # Focused responses\n",
        "                    \"repeat_penalty\": 1.1, # Reduce repetition\n",
        "                    \"num_ctx\": 4096       # Larger context window\n",
        "                }\n",
        "            },\n",
        "            timeout=180  # Longer timeout for 7B model\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.json().get(\"response\", \"No response\")\n",
        "        else:\n",
        "            return f\"❌ Error: Status {response.status_code}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error: {e}\"\n",
        "\n",
        "print(\"✅ Enhanced RAG function ready for Qwen 2.5-Coder!\")\n",
        "print(\"🎯 This model should excel at API documentation and technical questions!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmgGMbBQhG6s",
        "outputId": "5aa64935-2529-4d0c-a585-484dd2eeca52"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Enhanced RAG function ready for Qwen 2.5-Coder!\n",
            "🎯 This model should excel at API documentation and technical questions!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the RAG System\n",
        "test_questions = [\n",
        "    \"What is this RAG system about?\",\n",
        "    \"How do I troubleshoot issues?\",\n",
        "    \"What are the key components?\"\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Question: {question}\")\n",
        "    print('='*50)\n",
        "\n",
        "    answer = query_rag(question)\n",
        "    print(\"\\nAnswer:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(answer)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "print(\"\\n🎉 RAG System working on free GPU!\")"
      ],
      "metadata": {
        "id": "mySyWo50j33T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81bb194-2641-4a02-c99e-18f45532be15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Question: What is this RAG system about?\n",
            "==================================================\n",
            "🔍 Searching for: 'What is this RAG system about?'\n",
            "🤖 Asking gemma:2b...\n",
            "\n",
            "Answer:\n",
            "------------------------------\n",
            "This context does not provide information about what the RAG system is about, so I cannot answer this question from the provided context.\n",
            "------------------------------\n",
            "\n",
            "==================================================\n",
            "Question: How do I troubleshoot issues?\n",
            "==================================================\n",
            "🔍 Searching for: 'How do I troubleshoot issues?'\n",
            "🤖 Asking gemma:2b...\n",
            "\n",
            "Answer:\n",
            "------------------------------\n",
            "Sure, here are some steps on how to troubleshoot issues with the Local RAG system:\n",
            "\n",
            "1. Check the logs first.\n",
            "2. Review the system requirements.\n",
            "3. Consider posting detailed logs when seeking help.\n",
            "4. Try with minimal configuration first.\n",
            "5. Use specific, well-formed questions.\n",
            "6. Keep documents well-structured.\n",
            "7. Experiment with different chunk sizes.\n",
            "8. Try various LLM models for different use cases.\n",
            "------------------------------\n",
            "\n",
            "==================================================\n",
            "Question: What are the key components?\n",
            "==================================================\n",
            "🔍 Searching for: 'What are the key components?'\n",
            "🤖 Asking gemma:2b...\n",
            "\n",
            "Answer:\n",
            "------------------------------\n",
            "The key components of the system are:\n",
            "\n",
            "- PostgreSQL with pgvector\n",
            "- Sentence Transformers\n",
            "- Ollama\n",
            "- Data folder\n",
            "</start_of_turn>\n",
            "------------------------------\n",
            "\n",
            "🎉 RAG System working on free GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what documents are indexed\n",
        "print(\"📚 Currently indexed documents:\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Get all documents in the collection\n",
        "all_docs = collection.get()\n",
        "\n",
        "# Count by filename\n",
        "from collections import Counter\n",
        "filenames = [meta['filename'] for meta in all_docs['metadatas']]\n",
        "file_counts = Counter(filenames)\n",
        "\n",
        "for filename, count in file_counts.items():\n",
        "    print(f\"📄 {filename}: {count} chunks\")\n",
        "\n",
        "print(f\"\\n🔢 Total chunks: {len(all_docs['documents'])}\")\n",
        "\n",
        "# Show a sample chunk\n",
        "if all_docs['documents']:\n",
        "    print(f\"\\n📝 Sample chunk from {all_docs['metadatas'][0]['filename']}:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(all_docs['documents'][0][:200] + \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9i206F4RkSy",
        "outputId": "733e93e6-fb5e-40f7-81b3-59f4e3fe9432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📚 Currently indexed documents:\n",
            "========================================\n",
            "📄 troubleshooting.md: 2 chunks\n",
            "📄 sample.md: 1 chunks\n",
            "\n",
            "🔢 Total chunks: 3\n",
            "\n",
            "📝 Sample chunk from troubleshooting.md:\n",
            "------------------------------\n",
            "# Troubleshooting Guide This guide helps you resolve common issues with the local RAG system. ## Docker Issues ### Services Won't Start **Problem**: Docker containers fail to start or exit immediately...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Edit this cell to ask your own questions:\n",
        "# my_question = \"How do I get the max offset of a given topic and partition?\"\n",
        "# my_question = \"How do I create a connector?\"\n",
        "# my_question = \"What does the Confluent Cloud API do?\"\n",
        "my_question = \"Show me sample python code for creating a DatagenSource connector using the Confluent Cloud API\"\n",
        "\n",
        "print(f\"🎯 Your Question: {my_question}\")\n",
        "answer = query_rag(my_question, verbose=True)\n",
        "print(f\"\\n🤖 Answer:\\n{answer}\")\n",
        "\n",
        "print(\"\\n💡 Edit 'my_question' above and run again!\")\n",
        "print(\"\\n🚀 Your RAG POC is running 5-10x faster on free GPU!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CskR6DmISRA9",
        "outputId": "56768287-f881-466b-f2a7-6893f044d33b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Your Question: Show me sample python code for creating a DatagenSource connector using the Confluent Cloud API\n",
            "🔍 Searching for: 'Show me sample python code for creating a DatagenSource connector using the Confluent Cloud API'\n",
            "\n",
            "📄 Retrieved Context:\n",
            "📋 Chunk 1 [openapi] (Schema connect.v1.CustomConnectorPluginList): Data Model: connect.v1.CustomConnectorPluginList\n",
            "Type: object\n",
            "Description: CustomConnectorPlugins objects represent Custom Connector Plugins on Confluent Cloud.\n",
            "The API allows you to list, create, rea...\n",
            "----------------------------------------\n",
            "📋 Chunk 2 [openapi] (Schema pim.v1.IntegrationList): Data Model: pim.v1.IntegrationList\n",
            "Type: object\n",
            "Description: `Provider Integration` objects represent access to public cloud service provider (CSP) resources\n",
            "that may be accessed by Confluent resource...\n",
            "----------------------------------------\n",
            "📋 Chunk 3 [openapi] (Server Information): API Servers:\n",
            "- URL: https://api.confluent.cloud\n",
            "  Description: Confluent Cloud API...\n",
            "----------------------------------------\n",
            "📋 Chunk 4 [openapi] (Schema connect.v1.PresignedUrl): Data Model: connect.v1.PresignedUrl\n",
            "Type: object\n",
            "Description: Request a presigned upload URL for new Custom Connector Plugin. Note that\n",
            "the URL policy expires in one hour. If the policy expires, you c...\n",
            "----------------------------------------\n",
            "📋 Chunk 5 [openapi] (API Overview): API Name: Confluent Cloud APIs\n",
            "Version: \n",
            "Description: # Introduction\n",
            "\n",
            "<div class=\"status-info\">\n",
            "<p class=\"status-info-title\">Note</p>\n",
            "This documents the collection of Confluent Cloud APIs. Each API do...\n",
            "----------------------------------------\n",
            "🤖 Asking qwen2.5-coder:7b-instruct...\n",
            "\n",
            "🤖 Answer:\n",
            "To create a DatagenSource connector using the Confluent Cloud API, you can use the following Python code:\n",
            "\n",
            "```python\n",
            "import requests\n",
            "import json\n",
            "\n",
            "# Define the API endpoint for creating a connector\n",
            "url = \"https://api.confluent.cloud/connectors\"\n",
            "\n",
            "# Set the headers with your API key and secret\n",
            "headers = {\n",
            "    \"Content-Type\": \"application/json\",\n",
            "    \"Authorization\": \"Basic <your_api_key>:<your_api_secret>\"\n",
            "}\n",
            "\n",
            "# Define the payload for the DatagenSource connector\n",
            "payload = {\n",
            "    \"name\": \"my-datagen-source-connector\",\n",
            "    \"config\": {\n",
            "        \"connector.class\": \"io.confluent.connect.datagen.DatagenConnector\",\n",
            "        \"tasks.max\": \"1\",\n",
            "        \"topics\": \"my-topic\",\n",
            "        \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\",\n",
            "        \"value.converter\": \"org.apache.kafka.connect.json.JsonConverter\",\n",
            "        \"value.converter.schemas.enable\": \"false\",\n",
            "        \"format\": \"json\",\n",
            "        \"schema.generation.enabled\": \"true\"\n",
            "    }\n",
            "}\n",
            "\n",
            "# Make a POST request to create the connector\n",
            "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
            "\n",
            "# Check the response status code and print the result\n",
            "if response.status_code == 201:\n",
            "    print(\"Connector created successfully:\", response.json())\n",
            "else:\n",
            "    print(\"Failed to create connector:\", response.status_code, response.text)\n",
            "```\n",
            "\n",
            "Make sure to replace `<your_api_key>` and `<your_api_secret>` with your actual Confluent Cloud API key and secret. Also, adjust the `payload` dictionary according to your specific requirements for the DatagenSource connector.\n",
            "\n",
            "💡 Edit 'my_question' above and run again!\n",
            "\n",
            "🚀 Your RAG POC is running 5-10x faster on free GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test questions optimized for Qwen 2.5-Coder\n",
        "technical_questions = [\n",
        "    \"How do I get the max offset of a given topic and partition?\",\n",
        "    \"How do I create a connector?\",\n",
        "    \"What does the Confluent Cloud API do?\",\n",
        "    \"Show me sample python code for creating a DatagenSource connector using the Confluent Cloud API\"\n",
        "]\n",
        "\n",
        "print(\"🧪 Testing Qwen 2.5-Coder's technical understanding...\")\n",
        "\n",
        "for question in technical_questions[:3]:  # Test first 3\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"🔍 Question: {question}\")\n",
        "    print('='*70)\n",
        "    answer = query_rag(question, verbose=True)\n",
        "    print(f\"\\n🤖 Qwen 2.5-Coder Answer:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(answer)\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fNsOWleaLbG",
        "outputId": "78855162-e70f-4454-f3a2-cb24692e16f9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 Testing Qwen 2.5-Coder's technical understanding...\n",
            "\n",
            "======================================================================\n",
            "🔍 Question: How do I get the max offset of a given topic and partition?\n",
            "======================================================================\n",
            "🔍 Searching for: 'How do I get the max offset of a given topic and partition?'\n",
            "\n",
            "📄 Retrieved Context:\n",
            "📋 Chunk 1 [openapi] (Schema connect.v1.Offsets): Data Model: connect.v1.Offsets\n",
            "Type: array\n",
            "Description: Array of offsets which are categorised into partitions....\n",
            "----------------------------------------\n",
            "📋 Chunk 2 [openapi] (Endpoint GET /kafka/v3/clusters/{cluster_id}/topics/{topic_name}/partitions): Endpoint: GET /kafka/v3/clusters/{cluster_id}/topics/{topic_name}/partitions\n",
            "Summary: List Partitions\n",
            "Description: [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Av...\n",
            "----------------------------------------\n",
            "📋 Chunk 3 [openapi] (Schema PartitionLevelTruncationData): Data Model: PartitionLevelTruncationData\n",
            "Type: object\n",
            "Description: No description\n",
            "\n",
            "Properties:\n",
            "- partition_id: integer - No description\n",
            "- offset_truncated_to: integer - No description\n",
            "- messages_trunc...\n",
            "----------------------------------------\n",
            "📋 Chunk 4 [openapi] (Endpoint GET /kafka/v3/clusters/{cluster_id}/topics/{topic_name}/partitions/{partition_id}): Endpoint: GET /kafka/v3/clusters/{cluster_id}/topics/{topic_name}/partitions/{partition_id}\n",
            "Summary: Get Partition\n",
            "Description: [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-G...\n",
            "----------------------------------------\n",
            "📋 Chunk 5 [openapi] (Schema connect.v1.AlterOffsetRequestType): Data Model: connect.v1.AlterOffsetRequestType\n",
            "Type: string\n",
            "Description: The type of alter operation. PATCH will update the offset to the provided values.\n",
            "The update will only happen for the partitions...\n",
            "----------------------------------------\n",
            "🤖 Asking qwen2.5-coder:7b-instruct...\n",
            "\n",
            "🤖 Qwen 2.5-Coder Answer:\n",
            "--------------------------------------------------\n",
            "To get the max offset of a given topic and partition, you can use the following endpoint:\n",
            "\n",
            "**Endpoint:** `GET /kafka/v3/clusters/{cluster_id}/topics/{topic_name}/partitions`\n",
            "\n",
            "**HTTP Method:** `GET`\n",
            "\n",
            "**Parameters:**\n",
            "- `{cluster_id}`: The ID of your Kafka cluster.\n",
            "- `{topic_name}`: The name of the topic for which you want to retrieve the max offset.\n",
            "\n",
            "This endpoint will return a list of partitions, and each partition object will contain information about its offsets. To find the max offset, you would need to look at the `offsets` array in the response and identify the highest value among them.\n",
            "\n",
            "Here is an example of how you might parse this data:\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"partitions\": [\n",
            "    {\n",
            "      \"partition_id\": 0,\n",
            "      \"offsets\": [\n",
            "        {\n",
            "          \"offset\": 12345,\n",
            "          \"timestamp\": \"2023-04-01T12:00:00Z\"\n",
            "        },\n",
            "        {\n",
            "          \"offset\": 67890,\n",
            "          \"timestamp\": \"2023-04-01T12:01:00Z\"\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"partition_id\": 1,\n",
            "      \"offsets\": [\n",
            "        {\n",
            "          \"offset\": 54321,\n",
            "          \"timestamp\": \"2023-04-01T12:02:00Z\"\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n",
            "\n",
            "In this example, the max offset for partition 0 is `67890`, and for partition 1, it is `54321`.\n",
            "\n",
            "If you need to get the max offset specifically for a given partition, you can filter the partitions array based on the desired `partition_id`.\n",
            "--------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "🔍 Question: How do I create a connector?\n",
            "======================================================================\n",
            "🔍 Searching for: 'How do I create a connector?'\n",
            "\n",
            "📄 Retrieved Context:\n",
            "📋 Chunk 1 [openapi] (Schema connect.v1.ConnectorExpansion): Data Model: connect.v1.ConnectorExpansion\n",
            "Type: object\n",
            "Description: Name of connector\n",
            "\n",
            "Properties:\n",
            "- id: object - The ID of connector.\n",
            "- info: object - Metadata of the connector.\n",
            "- status: object - St...\n",
            "----------------------------------------\n",
            "📋 Chunk 2 [openapi] (Schema connect.v1.ConnectorOffsets): Data Model: connect.v1.ConnectorOffsets\n",
            "Type: object\n",
            "Description: Offsets for a connector\n",
            "\n",
            "Properties:\n",
            "- name: string - The name of the connector.\n",
            "- id: string - The ID of the connector.\n",
            "- offsets: un...\n",
            "----------------------------------------\n",
            "📋 Chunk 3 [openapi] (Schema connect.v1.Connectors): Data Model: connect.v1.Connectors\n",
            "Type: array\n",
            "Description: List of active task configs that have been created by the connector...\n",
            "----------------------------------------\n",
            "📋 Chunk 4 [openapi] (Schema connect.v1.ConnectorExpansionMap): Data Model: connect.v1.ConnectorExpansionMap\n",
            "Type: object\n",
            "Description: No description...\n",
            "----------------------------------------\n",
            "📋 Chunk 5 [openapi] (Schema connect.v1.PresignedUrl): Data Model: connect.v1.PresignedUrl\n",
            "Type: object\n",
            "Description: Request a presigned upload URL for new Custom Connector Plugin. Note that\n",
            "the URL policy expires in one hour. If the policy expires, you c...\n",
            "----------------------------------------\n",
            "🤖 Asking qwen2.5-coder:7b-instruct...\n",
            "\n",
            "🤖 Qwen 2.5-Coder Answer:\n",
            "--------------------------------------------------\n",
            "To create a connector, you would typically use an API endpoint that allows for the creation of new connectors. However, based on the provided context, there are no specific details about creating a connector directly through an API endpoint or method.\n",
            "\n",
            "If you are looking to upload a custom connector plugin, you can use the `PresignedUrl` schema to request a presigned URL for uploading your plugin archive. Here is how you might do it:\n",
            "\n",
            "1. **Request a Presigned URL**: Use the `/presigned-url` endpoint (assuming this exists) with an HTTP POST method. You would need to provide parameters such as `api_version`, `kind`, `content_format`, and `cloud`.\n",
            "\n",
            "2. **Upload the Plugin Archive**: Once you receive the presigned URL, you can upload your plugin archive using a PUT request to the provided URL.\n",
            "\n",
            "Here is an example of what the request might look like:\n",
            "\n",
            "```http\n",
            "POST /presigned-url HTTP/1.1\n",
            "Host: api.example.com\n",
            "Content-Type: application/json\n",
            "\n",
            "{\n",
            "  \"api_version\": \"connect.v1\",\n",
            "  \"kind\": \"CustomConnectorPlugin\",\n",
            "  \"content_format\": \"zip\",\n",
            "  \"cloud\": \"aws\"\n",
            "}\n",
            "```\n",
            "\n",
            "And here is an example of how you might upload the plugin archive:\n",
            "\n",
            "```http\n",
            "PUT /presigned-url/upload_id HTTP/1.1\n",
            "Host: presigned-upload.example.com\n",
            "Content-Type: application/octet-stream\n",
            "\n",
            "[Your plugin archive data]\n",
            "```\n",
            "\n",
            "If you need to create a connector through a different method, such as using a specific API endpoint or SDK, the context provided does not include details on how to do so. You would need to refer to additional documentation or contact support for more information.\n",
            "--------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "🔍 Question: What does the Confluent Cloud API do?\n",
            "======================================================================\n",
            "🔍 Searching for: 'What does the Confluent Cloud API do?'\n",
            "\n",
            "📄 Retrieved Context:\n",
            "📋 Chunk 1 [openapi] (API Overview): API Name: Confluent Cloud APIs\n",
            "Version: \n",
            "Description: # Introduction\n",
            "\n",
            "<div class=\"status-info\">\n",
            "<p class=\"status-info-title\">Note</p>\n",
            "This documents the collection of Confluent Cloud APIs. Each API do...\n",
            "----------------------------------------\n",
            "📋 Chunk 2 [openapi] (Server Information): API Servers:\n",
            "- URL: https://api.confluent.cloud\n",
            "  Description: Confluent Cloud API...\n",
            "----------------------------------------\n",
            "📋 Chunk 3 [openapi] (Schema pim.v1.AwsIntegrationConfig): Data Model: pim.v1.AwsIntegrationConfig\n",
            "Type: object\n",
            "Description: config schema for AWS cloud service provider.\n",
            "\n",
            "\n",
            "Properties:\n",
            "- iam_role_arn: string - Amazon Resource Name (ARN) that identifies the Am...\n",
            "----------------------------------------\n",
            "📋 Chunk 4 [openapi] (Schema pim.v1.IntegrationList): Data Model: pim.v1.IntegrationList\n",
            "Type: object\n",
            "Description: `Provider Integration` objects represent access to public cloud service provider (CSP) resources\n",
            "that may be accessed by Confluent resource...\n",
            "----------------------------------------\n",
            "📋 Chunk 5 [openapi] (Schema iam.v2.ServiceAccount): Data Model: iam.v2.ServiceAccount\n",
            "Type: object\n",
            "Description: `ServiceAccount` objects are typically used to represent applications and other non-human principals\n",
            "that may access your Confluent resource...\n",
            "----------------------------------------\n",
            "🤖 Asking qwen2.5-coder:7b-instruct...\n",
            "\n",
            "🤖 Qwen 2.5-Coder Answer:\n",
            "--------------------------------------------------\n",
            "The Confluent Cloud API allows you to manage various resources within your Confluent Cloud organization. It provides endpoints for creating, retrieving, updating, and deleting service accounts, as well as managing provider integrations that allow access to public cloud service provider (CSP) resources.\n",
            "\n",
            "### Service Accounts Management\n",
            "\n",
            "- **Endpoint**: `/serviceaccounts`\n",
            "- **HTTP Methods**:\n",
            "  - `GET /serviceaccounts`: Retrieve a list of all service accounts.\n",
            "  - `POST /serviceaccounts`: Create a new service account.\n",
            "  - `GET /serviceaccounts/{id}`: Retrieve details of a specific service account.\n",
            "  - `PUT /serviceaccounts/{id}`: Update an existing service account.\n",
            "  - `DELETE /serviceaccounts/{id}`: Delete a service account.\n",
            "\n",
            "### Provider Integrations Management\n",
            "\n",
            "- **Endpoint**: `/integrations`\n",
            "- **HTTP Methods**:\n",
            "  - `GET /integrations`: Retrieve a list of all provider integrations.\n",
            "  - `POST /integrations`: Create a new provider integration.\n",
            "  - `GET /integrations/{id}`: Retrieve details of a specific provider integration.\n",
            "  - `PUT /integrations/{id}`: Update an existing provider integration.\n",
            "  - `DELETE /integrations/{id}`: Delete a provider integration.\n",
            "\n",
            "### Example Request\n",
            "\n",
            "To create a new service account, you would use the following HTTP request:\n",
            "\n",
            "```http\n",
            "POST /serviceaccounts HTTP/1.1\n",
            "Host: api.confluent.cloud\n",
            "Content-Type: application/json\n",
            "User-Agent: CoolToolName/1.2.3 (https://example.org/CoolTool/; CoolTool@example.org) UsedBaseLibrary/2.1.0\n",
            "\n",
            "{\n",
            "  \"api_version\": \"iam.v2.ServiceAccount/v1\",\n",
            "  \"kind\": \"ServiceAccount\",\n",
            "  \"metadata\": {},\n",
            "  \"display_name\": \"My Service Account\",\n",
            "  \"description\": \"A service account for my integration\"\n",
            "}\n",
            "```\n",
            "\n",
            "### Example Response\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"api_version\": \"iam.v2.ServiceAccount/v1\",\n",
            "  \"kind\": \"ServiceAccount\",\n",
            "  \"id\": \"service-account-id-12345\",\n",
            "  \"metadata\": {},\n",
            "  \"display_name\": \"My Service Account\",\n",
            "  \"description\": \"A service account for my integration\"\n",
            "}\n",
            "```\n",
            "\n",
            "This API provides a robust way to manage your Confluent Cloud resources programmatically, allowing you to automate and integrate with other systems seamlessly.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}